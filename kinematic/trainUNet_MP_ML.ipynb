{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds=xr.Dataset({'qc':qcXR,'qr':qrXR,'qi':qiXR,'qs':qsXR,'qg':qgXR,'qns':qnsXR,'qng':qngXR,'qnr':qnrXR,'qni':qniXR,'qv':qvXR,     'press':pressXR,'temp':tempXR,'dz':dzXR,'qc_tend':qc_tendXR,'qr_tend':qr_tendXR,'qi_tend':qi_tendXR,'qs_tend':qs_tendXR,'qg_tend':qg_tendXR,'qns_tend':qns_tendXR,'qng_tend':qng_tendXR,'qnr_tend':qnr_tendXR,'qni_tend':qni_tendXR,'qv_tend':qv_tendXR,'temp_tend':temp_tendXR})\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "with nc.Dataset(\"trainingData.nc\") as fh:\n",
    "    qc=fh.variables['qc'][:]\n",
    "    qr=fh.variables['qr'][:]\n",
    "    qi=fh.variables['qi'][:]\n",
    "    qs=fh.variables['qs'][:]\n",
    "    qg=fh.variables['qg'][:]\n",
    "    qns=fh.variables['qns'][:]\n",
    "    qng=fh.variables['qng'][:]\n",
    "    qnr=fh.variables['qnr'][:]\n",
    "    qni=fh.variables['qni'][:]\n",
    "    qv=fh.variables['qv'][:]\n",
    "    press=fh.variables['press'][:]\n",
    "    temp=fh.variables['temp'][:]\n",
    "    dz=fh.variables['dz'][:]\n",
    "    qc_tend=fh.variables['qc_tend'][:]\n",
    "    qr_tend=fh.variables['qr_tend'][:]\n",
    "    qi_tend=fh.variables['qi_tend'][:]\n",
    "    qs_tend=fh.variables['qs_tend'][:]\n",
    "    qg_tend=fh.variables['qg_tend'][:]\n",
    "    qns_tend=fh.variables['qns_tend'][:]\n",
    "    qng_tend=fh.variables['qng_tend'][:]\n",
    "    qnr_tend=fh.variables['qnr_tend'][:]\n",
    "    qni_tend=fh.variables['qni_tend'][:]\n",
    "    qv_tend=fh.variables['qv_tend'][:]\n",
    "    temp_tend=fh.variables['temp_tend'][:]\n",
    "    nt,nz=qc.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale variables using the standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "\n",
    "inputVars=[\"qc\",\"qr\",\"qi\",\"qs\",\"qg\",\"qns\",\"qng\",\"qnr\",\"qni\",\"qv\",\"press\",\"temp\",\"dz\"]\n",
    "outputVars=[\"qc_tend\",\"qr_tend\",\"qi_tend\",\"qs_tend\",\"qg_tend\",\"qns_tend\",\"qng_tend\",\"qnr_tend\",\"qni_tend\",\"qv_tend\",\"temp_tend\"]\n",
    "inputData={\"qc\":qc,\"qr\":qr,\"qi\":qi,\"qs\":qs,\"qg\":qg,\"qns\":qns,\"qng\":qng,\"qnr\":qnr,\"qni\":qni,\"qv\":qv,\"press\":press,\"temp\":temp,\"dz\":dz}\n",
    "outputData={\"qc_tend\":qc_tend,\"qr_tend\":qr_tend,\"qi_tend\":qi_tend,\"qs_tend\":qs_tend,\"qg_tend\":qg_tend,\"qns_tend\":qns_tend,\"qng_tend\":qng_tend,\"qnr_tend\":qnr_tend,\"qni_tend\":qni_tend,\"qv_tend\":qv_tend,\"temp_tend\":temp_tend}\n",
    "inputDataScaled={}\n",
    "outputDataScaled={}\n",
    "inputScalers={}\n",
    "outputScalers={}\n",
    "for var in inputVars:\n",
    "    inputScalers[var]=StandardScaler()\n",
    "    inputDataScaled[var]=inputScalers[var].fit_transform(inputData[var])\n",
    "for var in outputVars:\n",
    "    outputScalers[var]=StandardScaler()\n",
    "    outputDataScaled[var]=outputScalers[var].fit_transform(outputData[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(684284, 72, 13) (684284, 72, 11)\n"
     ]
    }
   ],
   "source": [
    "inputData=np.array([inputDataScaled[var] for var in inputVars]).T\n",
    "outputData=np.array([outputDataScaled[var] for var in outputVars]).T\n",
    "inputData=np.swapaxes(inputData,0,1)\n",
    "outputData=np.swapaxes(outputData,0,1)\n",
    "print(inputData.shape,outputData.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15450.283\n"
     ]
    }
   ],
   "source": [
    "print(dz[0,0:64].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(inputData,outputData,test_size=0.4,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410570, 72, 13) (273714, 72, 13) (410570, 72, 11) (273714, 72, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(inputScalers,open(\"inputScalers.pkl\",\"wb\"))\n",
    "pickle.dump(outputScalers,open(\"outputScalers.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 72, 13)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_69 (Conv1D)          (None, 72, 16)               640       ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_70 (Conv1D)          (None, 72, 16)               784       ['conv1d_69[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, 72, 16)               64        ['conv1d_70[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)        (None, 72, 16)               0         ['batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling1d_24 (MaxPooli  (None, 36, 16)               0         ['dropout_30[0][0]']          \n",
      " ng1D)                                                                                            \n",
      "                                                                                                  \n",
      " conv1d_71 (Conv1D)          (None, 36, 32)               1568      ['max_pooling1d_24[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_72 (Conv1D)          (None, 36, 32)               3104      ['conv1d_71[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (None, 36, 32)               128       ['conv1d_72[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)        (None, 36, 32)               0         ['batch_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling1d_25 (MaxPooli  (None, 18, 32)               0         ['dropout_31[0][0]']          \n",
      " ng1D)                                                                                            \n",
      "                                                                                                  \n",
      " conv1d_73 (Conv1D)          (None, 18, 64)               6208      ['max_pooling1d_25[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_74 (Conv1D)          (None, 18, 64)               12352     ['conv1d_73[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (None, 18, 64)               256       ['conv1d_74[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)        (None, 18, 64)               0         ['batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling1d_26 (MaxPooli  (None, 9, 64)                0         ['dropout_32[0][0]']          \n",
      " ng1D)                                                                                            \n",
      "                                                                                                  \n",
      " conv1d_75 (Conv1D)          (None, 9, 128)               24704     ['max_pooling1d_26[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_76 (Conv1D)          (None, 9, 128)               49280     ['conv1d_75[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (None, 9, 128)               512       ['conv1d_76[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)        (None, 9, 128)               0         ['batch_normalization_33[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling1d_27 (MaxPooli  (None, 5, 128)               0         ['dropout_33[0][0]']          \n",
      " ng1D)                                                                                            \n",
      "                                                                                                  \n",
      " conv1d_77 (Conv1D)          (None, 5, 256)               98560     ['max_pooling1d_27[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_78 (Conv1D)          (None, 5, 256)               196864    ['conv1d_77[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (None, 5, 256)               1024      ['conv1d_78[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)        (None, 5, 256)               0         ['batch_normalization_34[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_transpose_6 (Conv1D  (None, 10, 128)              98432     ['dropout_34[0][0]']          \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 9, 128)               0         ['conv1d_transpose_6[0][0]']  \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 9, 256)               0         ['tf.__operators__.getitem_2[0\n",
      " )                                                                  ][0]',                        \n",
      "                                                                     'dropout_33[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_79 (Conv1D)          (None, 9, 128)               98432     ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_80 (Conv1D)          (None, 9, 128)               49280     ['conv1d_79[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_transpose_7 (Conv1D  (None, 18, 64)               24640     ['conv1d_80[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 18, 128)              0         ['conv1d_transpose_7[0][0]',  \n",
      " )                                                                   'dropout_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_81 (Conv1D)          (None, 18, 64)               24640     ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_82 (Conv1D)          (None, 18, 64)               12352     ['conv1d_81[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_transpose_8 (Conv1D  (None, 36, 32)               6176      ['conv1d_82[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate  (None, 36, 64)               0         ['conv1d_transpose_8[0][0]',  \n",
      " )                                                                   'dropout_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_83 (Conv1D)          (None, 36, 32)               6176      ['concatenate_8[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_84 (Conv1D)          (None, 36, 32)               3104      ['conv1d_83[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 36, 32)               0         ['conv1d_84[0][0]']           \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " conv1d_transpose_9 (Conv1D  (None, 72, 32)               3104      ['tf.__operators__.getitem_3[0\n",
      " Transpose)                                                         ][0]']                        \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate  (None, 72, 48)               0         ['conv1d_transpose_9[0][0]',  \n",
      " )                                                                   'dropout_30[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_85 (Conv1D)          (None, 72, 32)               4640      ['concatenate_9[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_86 (Conv1D)          (None, 72, 32)               3104      ['conv1d_85[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_87 (Conv1D)          (None, 72, 11)               363       ['conv1d_86[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 730491 (2.79 MB)\n",
      "Trainable params: 729499 (2.78 MB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from uNet1D import *\n",
    "\n",
    "model=unet1D(input_size=(72,13), nout=11, n_filters=[16])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12831/12831 [==============================] - 295s 23ms/step - loss: 0.4944 - mse: 0.4944 - val_loss: 0.3699 - val_mse: 0.3699\n",
      "Epoch 2/30\n",
      "12831/12831 [==============================] - 293s 23ms/step - loss: 0.3934 - mse: 0.3934 - val_loss: 0.3338 - val_mse: 0.3338\n",
      "Epoch 3/30\n",
      "12831/12831 [==============================] - 293s 23ms/step - loss: 0.3836 - mse: 0.3836 - val_loss: 0.3210 - val_mse: 0.3210\n",
      "Epoch 4/30\n",
      "12831/12831 [==============================] - 293s 23ms/step - loss: 0.3657 - mse: 0.3657 - val_loss: 0.3132 - val_mse: 0.3132\n",
      "Epoch 5/30\n",
      "12831/12831 [==============================] - 293s 23ms/step - loss: 0.3614 - mse: 0.3614 - val_loss: 0.3151 - val_mse: 0.3151\n",
      "Epoch 6/30\n",
      "12831/12831 [==============================] - 294s 23ms/step - loss: 0.3475 - mse: 0.3475 - val_loss: 0.3173 - val_mse: 0.3173\n",
      "Epoch 7/30\n",
      "12831/12831 [==============================] - 294s 23ms/step - loss: 0.3379 - mse: 0.3379 - val_loss: 0.2980 - val_mse: 0.2980\n",
      "Epoch 8/30\n",
      "12831/12831 [==============================] - 295s 23ms/step - loss: 0.3381 - mse: 0.3381 - val_loss: 0.3016 - val_mse: 0.3016\n",
      "Epoch 9/30\n",
      "12831/12831 [==============================] - 293s 23ms/step - loss: 0.3337 - mse: 0.3337 - val_loss: 0.3035 - val_mse: 0.3035\n",
      "Epoch 10/30\n",
      "  292/12831 [..............................] - ETA: 4:04 - loss: 0.2872 - mse: 0.2872"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m,metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m hist\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(X_train,y_train,epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(X_test,y_test))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='mse',metrics=['mse'])\n",
    "hist=model.fit(X_train,y_train,epochs=30,batch_size=32,validation_data=(X_test,y_test))\n",
    "#y_=model.predict(X_train[0:1,:,:])\n",
    "#print(y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"unet1D_MP_ML.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "from keras.models import load_model\n",
    "model=load_model(\"unet1D_MP_ML.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8554/8554 [==============================] - 46s 5ms/step\n",
      "time to predict= 48.00339674949646\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0=time.time()\n",
    "y_=model.predict(X_test[:,:,:])\n",
    "t1=time.time()\n",
    "print(\"time to predict=\",t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.16941694169417\n",
      "qc_tend 0.8670579489733449\n",
      "qr_tend 0.7870705929611977\n",
      "qi_tend 0.7859893413564109\n",
      "qs_tend 0.8684453714733126\n",
      "qg_tend 0.9094923433196229\n",
      "qns_tend 0.5142148886485024\n",
      "qng_tend 0.6888834950147088\n",
      "qnr_tend 0.9133099971930863\n",
      "qni_tend 0.5552458311705498\n",
      "qv_tend 0.838947535990423\n",
      "temp_tend 0.8399929499070017\n"
     ]
    }
   ],
   "source": [
    "print(y_.shape[0]/(189*202))\n",
    "for i,var in enumerate(outputVars):\n",
    "    print(var,np.corrcoef(y_[:,:,i].flatten(),y_test[:,:,i].flatten())[0,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
